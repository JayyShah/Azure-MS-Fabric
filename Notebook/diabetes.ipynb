{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a machine learning model to predict diabetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Azure storage access info for open dataset diabetes\n",
    "blob_account_name = \"azureopendatastorage\"\n",
    "blob_container_name = \"mlsamples\"\n",
    "blob_relative_path = \"diabetes\"\n",
    "blob_sas_token = r\"\" # Blank since container is Anonymous access\n",
    "\n",
    "# Set Spark config to access  blob storage\n",
    "wasbs_path = f\"wasbs://%s@%s.blob.core.windows.net/%s\" % (blob_container_name, blob_account_name, blob_relative_path)\n",
    "spark.conf.set(\"fs.azure.sas.%s.%s.blob.core.windows.net\" % (blob_container_name, blob_account_name), blob_sas_token)\n",
    "print(\"Remote blob path: \" + wasbs_path)\n",
    "\n",
    "# Spark read parquet, note that it won't load any data yet by now\n",
    "df = spark.read.parquet(wasbs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Spark dataframe to a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = df.toPandas()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = df[['AGE','SEX','BMI','BP','S1','S2','S3','S4','S5','S6']].values, df['Y'].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an experiment in the workspace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "experiment_name = \"experiment-diabetes\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and track the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from mlflow.models.signature import ModelSignature\n",
    "from mlflow.types.schema import Schema, ColSpec\n",
    "\n",
    "with mlflow.start_run():\n",
    "   mlflow.autolog(log_models=False)\n",
    "\n",
    "   model = DecisionTreeRegressor(max_depth=5) \n",
    "   model.fit(X_train, y_train)\n",
    "\n",
    "   # create the signature manually\n",
    "   input_schema = Schema([\n",
    "   ColSpec(\"integer\", \"AGE\"),\n",
    "   ColSpec(\"integer\", \"SEX\"),\n",
    "   ColSpec(\"double\", \"BMI\"),\n",
    "   ColSpec(\"double\", \"BP\"),\n",
    "   ColSpec(\"integer\", \"S1\"),\n",
    "   ColSpec(\"double\", \"S2\"),\n",
    "   ColSpec(\"double\", \"S3\"),\n",
    "   ColSpec(\"double\", \"S4\"),\n",
    "   ColSpec(\"double\", \"S5\"),\n",
    "   ColSpec(\"integer\", \"S6\"),\n",
    "   ])\n",
    "\n",
    "   output_schema = Schema([ColSpec(\"integer\")])\n",
    "\n",
    "   # Create the signature object\n",
    "   signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n",
    "\n",
    "   # manually log the model\n",
    "   mlflow.sklearn.log_model(model, \"model\", signature=signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the model is trained and tracked in an experiment, you can register the model from the latest experiment run output. Start by retrieving the latest run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = mlflow.get_experiment_by_name(experiment_name)\n",
    "\n",
    "last_run = mlflow.search_runs(exp.experiment_id, order_by=[\"start_time DESC\"], max_results=1)\n",
    "\n",
    "last_run_id = last_run.iloc[0][\"run_id\"]\n",
    "\n",
    "print(\"Last Run ID:\", last_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model URI by specifying the model output folder to which all model artifacts are stored and including the experiment run ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_uri = \"runs:/{}/model\".format(last_run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model by registering it to the workspace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv = mlflow.register_model(model_uri, \"diabetes-model\")\n",
    "\n",
    "print(\"Name: {}\".format(mv.name))\n",
    "print(\"Version: {}\".format(mv.version))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your model is now saved in your workspace under the name diabetes-model.\n",
    "\n",
    "###  Optionally, you can use the browse feature in your workspace to find the model in the workspace and explore it using the UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a test dataset and save in a lakehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before running the cell below, complete the following steps:\n",
    "\n",
    "- In the Add lakehouse pane, select Add to add a lakehouse.\n",
    "1. Select New lakehouse and select Add.\n",
    "2. Create a new Lakehouse with a name of your choice.\n",
    "3. When asked to stop the current session, select Stop now to restart the notebook.\n",
    "4. When the lakehouse is created and attached to this notebook, run the following cell to create a test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the dataframe with test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    (62, 2, 33.7, 101.0, 157, 93.2, 38.0, 4.0, 4.8598, 87),\n",
    "    (50, 1, 22.7, 87.0, 183, 103.2, 70.0, 3.0, 3.8918, 69),\n",
    "    (76, 2, 32.0, 93.0, 156, 93.6, 41.0, 4.0, 4.6728, 85),\n",
    "    (25, 1, 26.6, 84.0, 198, 131.4, 40.0, 5.0, 4.8903, 89),\n",
    "    (53, 1, 23.0, 101.0, 192, 125.4, 52.0, 4.0, 4.2905, 80),\n",
    "    (24, 1, 23.7, 89.0, 139, 64.8, 61.0, 2.0, 4.1897, 68),\n",
    "    (38, 2, 22.0, 90.0, 160, 99.6, 50.0, 3.0, 3.9512, 82),\n",
    "    (69, 2, 27.5, 114.0, 255, 185.0, 56.0, 5.0, 4.2485, 92),\n",
    "    (63, 2, 33.7, 83.0, 179, 119.4, 42.0, 4.0, 4.4773, 94),\n",
    "    (30, 1, 30.0, 85.0, 180, 93.4, 43.0, 4.0, 5.3845, 88)\n",
    "]\n",
    "\n",
    "columns = ['AGE','SEX','BMI','BP','S1','S2','S3','S4','S5','S6']\n",
    "\n",
    "df = spark.createDataFrame(data, schema=columns)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the data types of the columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change the data types for the columns to align with the model's expected input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import IntegerType, DoubleType\n",
    "\n",
    "df = df.withColumn(\"AGE\", df[\"AGE\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"SEX\", df[\"SEX\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"BMI\", df[\"BMI\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"BP\", df[\"BP\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"S1\", df[\"S1\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"S2\", df[\"S2\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"S3\", df[\"S3\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"S4\", df[\"S4\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"S5\", df[\"S5\"].cast(DoubleType()))\n",
    "df = df.withColumn(\"S6\", df[\"S6\"].cast(IntegerType()))\n",
    "\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the test dataset in the lakehouse as a Delta table named diabetes_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"diabetes_test\"\n",
    "df.write.format(\"delta\").mode(\"overwrite\").save(f\"Tables/{table_name}\")\n",
    "print(f\"Spark dataframe saved to delta table: {table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To view the delta table, select the ... next to the Tables in the Lakehouse explorer pane, and select Refresh. The diabetes_test table should appear.\n",
    "\n",
    "#### Expand the diabetes_test table in the left pane to view all fields it includes. Note that there's no field named predictions yet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the model to generate predictions\n",
    "\n",
    "- Finally, you can apply the model you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from synapse.ml.predict import MLFlowTransformer\n",
    "\n",
    "df_test = spark.read.format(\"delta\").load(f\"Tables/{table_name}\")\n",
    "\n",
    "model = MLFlowTransformer(\n",
    "    inputCols=[\"AGE\",\"SEX\",\"BMI\",\"BP\",\"S1\",\"S2\",\"S3\",\"S4\",\"S5\",\"S6\"],\n",
    "    outputCol=\"predictions\",\n",
    "    modelName=\"diabetes-model\",\n",
    "    modelVersion=1\n",
    ")\n",
    "df_test = model.transform(df)\n",
    "\n",
    "df_test.write.format('delta').mode(\"overwrite\").option(\"mergeSchema\", \"true\").save(f\"Tables/{table_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select the ... next to the diabetes_test table and select Refresh. A new field predictions has been added.\n",
    "\n",
    "#### Drag and drop the diabetes_test table to the field below. The necessary code to view the table's contents will appear. Run the cell to visualize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
